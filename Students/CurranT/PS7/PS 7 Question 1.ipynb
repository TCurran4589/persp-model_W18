{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tom Curran\n",
    "\n",
    "Problem set \\#7 \n",
    "\n",
    "March 5, 2018\n",
    "\n",
    "---\n",
    "\n",
    "Classifier “horse” race (10 points). For this problem, you will use the 397 observationsfromtheAuto.csvdataset.1 Thisdatasetincludes397observations on miles per gallon (mpg), number of cylinders (cylinders), engine displace- ment (displacement), horsepower (horsepower), vehicle weight (weight), ac- celeration (acceleration), vehicle year (year), vehicle origin (origin), and vehicle name (name). We will study the factors that make miles per gallon high or low. Create a binary variable mpg high that equals 1 if mpg high≥ median(mpg high) and equals either 0 if mpg high< median(mpg high).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Use sklearn.linear model.LogisticRegression to fit a logistic model of mpg high on features number of cylinders (cyl), engine displacement (dspl), horsepower (hpwr), vehicle weight (wgt), acceleration (accl), vehi- cle year (yr), vehicle origin (orgn). Make sure to include a constant term. Fit the model using k-fold cross validation with k = 4 folds.2\n",
    "Report the MSE of the model as the average MSE across the k = 4 test sets, and report the error rates for each category of mpg high as the average error rate for that category across the k = 4 test sets.\n",
    "\n",
    "$$ Pr(mpg_high = 1 | X \\beta) =\\frac{e^{X\\beta}}{1 + e^{X\\beta}} $$\n",
    "\n",
    "where \n",
    "$$X\\beta = \\beta_0 + \\beta_1cyl_i + \\beta_2dspl_i + \\beta_3hpwr_i + \\beta_4wgt_i + \\beta_5accl_i+ \\beta_6yr_i + \\beta_7orgn_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomascurran/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"Auto.csv\", na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      5\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleanup\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 392 entries, 0 to 396\n",
      "Data columns (total 9 columns):\n",
      "mpg             392 non-null float64\n",
      "cylinders       392 non-null int64\n",
      "displacement    392 non-null float64\n",
      "horsepower      392 non-null float64\n",
      "weight          392 non-null int64\n",
      "acceleration    392 non-null float64\n",
      "year            392 non-null int64\n",
      "origin          392 non-null int64\n",
      "name            392 non-null object\n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 30.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.445918</td>\n",
       "      <td>5.471939</td>\n",
       "      <td>194.411990</td>\n",
       "      <td>104.469388</td>\n",
       "      <td>2977.584184</td>\n",
       "      <td>15.541327</td>\n",
       "      <td>75.979592</td>\n",
       "      <td>1.576531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.805007</td>\n",
       "      <td>1.705783</td>\n",
       "      <td>104.644004</td>\n",
       "      <td>38.491160</td>\n",
       "      <td>849.402560</td>\n",
       "      <td>2.758864</td>\n",
       "      <td>3.683737</td>\n",
       "      <td>0.805518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2225.250000</td>\n",
       "      <td>13.775000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>2803.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>275.750000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>3614.750000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  horsepower       weight  \\\n",
       "count  392.000000  392.000000    392.000000  392.000000   392.000000   \n",
       "mean    23.445918    5.471939    194.411990  104.469388  2977.584184   \n",
       "std      7.805007    1.705783    104.644004   38.491160   849.402560   \n",
       "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
       "25%     17.000000    4.000000    105.000000   75.000000  2225.250000   \n",
       "50%     22.750000    4.000000    151.000000   93.500000  2803.500000   \n",
       "75%     29.000000    8.000000    275.750000  126.000000  3614.750000   \n",
       "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
       "\n",
       "       acceleration        year      origin  \n",
       "count    392.000000  392.000000  392.000000  \n",
       "mean      15.541327   75.979592    1.576531  \n",
       "std        2.758864    3.683737    0.805518  \n",
       "min        8.000000   70.000000    1.000000  \n",
       "25%       13.775000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.025000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(len(df.columns), 'constant', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mpg_high'] = df.mpg.apply(lambda x: 1 if x>= df.mpg.median() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>constant</th>\n",
       "      <th>mpg_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  constant  mpg_high  \n",
       "0       1  chevrolet chevelle malibu         1         0  \n",
       "1       1          buick skylark 320         1         0  \n",
       "2       1         plymouth satellite         1         0  \n",
       "3       1              amc rebel sst         1         0  \n",
       "4       1                ford torino         1         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['mpg_high'])\n",
    "\n",
    "x = np.array(df[['cylinders','displacement','horsepower', 'weight','acceleration','year', 'origin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =4\n",
    "\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 15)\n",
    "\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "mse = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 9.18%\n",
      "Error Rate for 0:   5.77%\n",
      "Error Rate for 1:   13.04%\n",
      "\n",
      "Classification Report for K = 1 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        55\n",
      "          1       0.87      0.93      0.90        43\n",
      "\n",
      "avg / total       0.91      0.91      0.91        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 10.2%\n",
      "Error Rate for 0:   12.24%\n",
      "Error Rate for 1:   8.16%\n",
      "\n",
      "Classification Report for K = 2 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90        47\n",
      "          1       0.92      0.88      0.90        51\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 13.27%\n",
      "Error Rate for 0:   15.22%\n",
      "Error Rate for 1:   11.54%\n",
      "\n",
      "Classification Report for K = 3 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        45\n",
      "          1       0.88      0.87      0.88        53\n",
      "\n",
      "avg / total       0.87      0.87      0.87        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 10.2%\n",
      "Error Rate for 0:   4.65%\n",
      "Error Rate for 1:   14.55%\n",
      "\n",
      "Classification Report for K = 4 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89        49\n",
      "          1       0.85      0.96      0.90        49\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Total Error Rates\n",
      "Mean Squared Error:                    10.71%\n",
      "Mean Squared Error Standard Deviation: 0.01531\n",
      "Error Rate for 0:                      4.65%\n",
      "Error Rate for 1:                      14.55%\n"
     ]
    }
   ],
   "source": [
    "#begin logistic regression with k = 4 folds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, mean_squared_error, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "yval_test = np.zeros(x.shape[0])\n",
    "\n",
    "yval_pred = np.zeros(x.shape[0])\n",
    "\n",
    "k_index = 0\n",
    "\n",
    "mse1 = np.zeros(k)\n",
    "\n",
    "mse0 = np.zeros(k)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    xtrain, xtest = x[train_index], x[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    \n",
    "    logreg.fit(xtrain, ytrain)\n",
    "    \n",
    "    yhat = logreg.predict(xtest)\n",
    "    \n",
    "    yval_test[test_index] = ytest\n",
    "    \n",
    "    yval_pred[test_index] = yhat\n",
    "    \n",
    "    mse[k_index] = mean_squared_error(ytest, yhat)\n",
    "        #print(accuracy_score(ytest, yhat))\n",
    "    prec = precision_recall_fscore_support(ytest, yhat)\n",
    "    \n",
    "    zero_errorRate = 1 - prec[0][0]\n",
    "    one_errorRate = 1 - prec[0][1]\n",
    "    \n",
    "    mse1[k_index] = one_errorRate\n",
    "    mse0[k_index] = zero_errorRate\n",
    "\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"Mean Squared Error:\", str(round(mse[k_index],4)*100)+'%')\n",
    "    print(\"Error Rate for 0:  \",  str(round(zero_errorRate,4)*100)+'%')\n",
    "    print(\"Error Rate for 1:  \",str(round(one_errorRate,4)*100)+'%')\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Classification Report for K =\", k_index+1,\":\")\n",
    "    print(classification_report(ytest, yhat))\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "\n",
    "    k_index += 1\n",
    "    \n",
    "    \n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"Total Error Rates\")\n",
    "print(\"Mean Squared Error:                   \", str(round(mse.mean(),4)*100)+'%')\n",
    "print(\"Mean Squared Error Standard Deviation:\", str(round(mse.std(),5)))\n",
    "print(\"Error Rate for 0:                     \", str(round(zero_errorRate.mean(),4)*100)+'%')\n",
    "print(\"Error Rate for 1:                     \", str(round(one_errorRate.mean(),4)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "b) Use sklearn.ensemble.RandomForestClassifier to fit a random for- est model of mpg high on max features=2 out of the seven possible fea- tures used in part (a). Set n estimators=20, set bootstrap=True, set oob score=True, and set random state=25. Report the MSE of the ran- dom forest model as the MSE from the .oob prediction object, and re- port the error rates for each category of mpg high from the .oob prediction object.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sklearn.ensemble.RandomForestClassifier(n_estimators=10, \n",
    "                                        criterion=’gini’, \n",
    "                                        max_depth=None, \n",
    "                                        min_samples_split=2, \n",
    "                                        min_samples_leaf=1, \n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        max_features=’auto’, \n",
    "                                        max_leaf_nodes=None, \n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None, \n",
    "                                        bootstrap=True, \n",
    "                                        oob_score=False, \n",
    "                                        n_jobs=1, \n",
    "                                        random_state=None, \n",
    "                                        verbose=0, \n",
    "                                        warm_start=False, class_weight=None)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 20, \n",
    "                           max_features = 2, \n",
    "                           bootstrap = True, \n",
    "                           oob_score = True, \n",
    "                           random_state = 25\n",
    "                          )\n",
    "\n",
    "rf.fit(x,y)\n",
    "\n",
    "yhat = rf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Zero MSE:  5.789%\n",
      "Category One MSE:   8.416%\n",
      "------------------------------------------------------------------------------\n",
      "Totale MSE:         7.143%\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame(yhat).rename(columns = {0:'zero', 1:'one'})\n",
    "\n",
    "pred['y'] = y\n",
    "\n",
    "pred['oob_prediction'] = pred.one.apply(lambda x: 1 if x >= .5 else 0)\n",
    "\n",
    "total_mse = mean_squared_error(pred.y, pred.oob_prediction)\n",
    "\n",
    "mse_zero = pred[pred['oob_prediction'] == 0]\n",
    "mse_zero_val = mean_squared_error(mse_zero.y, mse_zero.oob_prediction)\n",
    "\n",
    "mse_one = pred[pred['oob_prediction'] == 1]\n",
    "mse_one_val = mean_squared_error(mse_one.y, mse_one.oob_prediction)\n",
    "\n",
    "print(\"Category Zero MSE: \",str(round(mse_zero_val, 5)*100) + '%')\n",
    "print(\"Category One MSE:  \", str(round(mse_one_val, 5)*100) + '%')\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"Totale MSE:        \",str(round(total_mse, 5)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Random Forest Regressor: 0.0582693449267\n",
      "OOB Prediction Accuracy Score:0.766922620293\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators = 20, \n",
    "                                   max_features = 2, \n",
    "                                   bootstrap = True, \n",
    "                                   oob_score = True, \n",
    "                                   random_state = 25\n",
    "                                  )\n",
    "rf_reg.fit(x,y)\n",
    "\n",
    "rf_reg.score(x,y)\n",
    "\n",
    "yhat_rfreg = rf_reg.oob_prediction_\n",
    "mse_reg = mean_squared_error(y, yhat_rfreg)\n",
    "\n",
    "print(\"Mean Squared Error for Random Forest Regressor: \" + str(mse_reg))\n",
    "print(\"OOB Prediction Accuracy Score:\"+str(rf_reg.oob_score_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "c) Use sklearn.svm.SVC to fit a support vector machines model of mpg high with a Gaussian radial basis function kernel kernel=’rbf’ on the seven features used in part (a). Set the penalty parameter to C=1 and set gamma=0.2. Fit the model using k-fold cross validation with k = 4 folds exactly as in part (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "k =4\n",
    "\n",
    "kf_svm = KFold(n_splits = k, shuffle = True, random_state = 15)\n",
    "\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "mse_svm = np.zeros(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 54.08%\n",
      "Error Rate for 0:   0.0%\n",
      "Error Rate for 1:   55.21%\n",
      "\n",
      "Classification Report for K = 1 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07        55\n",
      "          1       0.45      1.00      0.62        43\n",
      "\n",
      "avg / total       0.76      0.46      0.31        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 52.04%\n",
      "Error Rate for 0:   52.04%\n",
      "Error Rate for 1:   100.0%\n",
      "\n",
      "Classification Report for K = 2 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        47\n",
      "          1       0.00      0.00      0.00        51\n",
      "\n",
      "avg / total       0.23      0.48      0.31        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 52.04%\n",
      "Error Rate for 0:   53.12%\n",
      "Error Rate for 1:   0.0%\n",
      "\n",
      "Classification Report for K = 3 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      1.00      0.64        45\n",
      "          1       1.00      0.04      0.07        53\n",
      "\n",
      "avg / total       0.76      0.48      0.33        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Mean Squared Error: 44.9%\n",
      "Error Rate for 0:   47.31%\n",
      "Error Rate for 1:   0.0%\n",
      "\n",
      "Classification Report for K = 4 :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      1.00      0.69        49\n",
      "          1       1.00      0.10      0.19        49\n",
      "\n",
      "avg / total       0.76      0.55      0.44        98\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Total Mean Squared Error: 50.77%\n",
      "Total Mean Squared Error Standard Deviation: 0.0349\n",
      "Error Rate for 0:   14.55%\n",
      "Error Rate for 1:   4.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomascurran/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yval_test = np.zeros(x.shape[0])\n",
    "\n",
    "yval_pred = np.zeros(x.shape[0])\n",
    "\n",
    "k_index = 0\n",
    "\n",
    "mse1_svm = np.zeros(k)\n",
    "\n",
    "mse0_svm = np.zeros(k)\n",
    "\n",
    "for train_index, test_index in kf_svm.split(x):\n",
    "    xtrain, xtest = x[train_index], x[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = svm.SVC(kernel = 'rbf', C=1, gamma = .2)\n",
    "    \n",
    "    clf.fit(xtrain, ytrain)\n",
    "    \n",
    "    yhat = clf.predict(xtest)\n",
    "\n",
    "    yval_test[test_index] = ytest\n",
    "    \n",
    "    yval_pred[test_index] = yhat\n",
    "    \n",
    "    mse_svm[k_index] = mean_squared_error(ytest, yhat)\n",
    "    prec = precision_recall_fscore_support(ytest, yhat)\n",
    "    \n",
    "    zero_errorRate_svm = 1 - prec[0][0]\n",
    "    one_errorRate_svm = 1 - prec[0][1]\n",
    "    \n",
    "    mse1_svm[k_index] = one_errorRate\n",
    "    mse0_svm[k_index] = zero_errorRate\n",
    "\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"Mean Squared Error:\", str(round(mse_svm[k_index],4)*100)+'%')\n",
    "    print(\"Error Rate for 0:  \",  str(round(zero_errorRate_svm,4)*100)+'%')\n",
    "    print(\"Error Rate for 1:  \",str(round(one_errorRate_svm,4)*100)+'%')\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Classification Report for K =\", k_index+1,\":\")\n",
    "    print(classification_report(ytest, yhat))\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    k_index += 1\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"Total Mean Squared Error:\", str(round(mse_svm.mean(),4)*100)+'%')\n",
    "print(\"Total Mean Squared Error Standard Deviation:\", str(round(mse_svm.std(),4)))\n",
    "print(\"Error Rate for 0:  \",  str(round(mse1_svm.mean(),4)*100)+'%')\n",
    "print(\"Error Rate for 1:  \",str(round(mse0_svm.mean(),4)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "(d) Which of the above three models do you think is the best predictor of mpg high? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame({\"Value\":['mse', 'mse 0', 'mse 1'],\n",
    "                          \"Logit\":[mse.mean(), zero_errorRate.mean(), one_errorRate.mean()],\n",
    "                          \"Random_Forest\":[total_mse, mse_zero_val, mse_one_val],\n",
    "                          \"SVM\":[0,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>Total MSE</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logit</td>\n",
       "      <td>MSE 1</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit</td>\n",
       "      <td>MSE 0</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Total MSE</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MSE 1</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MSE 0</td>\n",
       "      <td>0.057895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Total MSE</td>\n",
       "      <td>0.507653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>MSE 1</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>MSE 0</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model   Variable    Values\n",
       "0          Logit  Total MSE  0.107143\n",
       "1          Logit      MSE 1  0.145455\n",
       "2          Logit      MSE 0  0.046512\n",
       "3  Random Forest  Total MSE  0.071429\n",
       "4  Random Forest      MSE 1  0.084158\n",
       "5  Random Forest      MSE 0  0.057895\n",
       "6            SVM  Total MSE  0.507653\n",
       "7            SVM      MSE 1  0.145455\n",
       "8            SVM      MSE 0  0.046512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({'model':['Logit','Logit','Logit', 'Random Forest', 'Random Forest','Random Forest', \"SVM\", \"SVM\", \"SVM\"]})\n",
    "\n",
    "models['Variable'] = ['Total MSE', 'MSE 1', 'MSE 0', 'Total MSE', 'MSE 1', 'MSE 0','Total MSE', 'MSE 1', 'MSE 0']\n",
    "\n",
    "models['Values'] = [mse.mean(), \n",
    "                    one_errorRate.mean(),\n",
    "                    zero_errorRate.mean(),\n",
    "                    total_mse, \n",
    "                    mse_one_val, \n",
    "                    mse_zero_val,\n",
    "                    mse_svm.mean(),\n",
    "                    mse1_svm.mean(), \n",
    "                    mse0_svm.mean()]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomascurran/anaconda/lib/python3.6/site-packages/seaborn/categorical.py:1468: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data[hue_mask])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGoCAYAAAAq471qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCqBJ/tWQ5SEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115641b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Draw a nested barplot to show survival for class and sex\n",
    "g = sns.factorplot(x=\"Variable\", y=\"Values\", hue=\"model\", data=models,\n",
    "                   size=6, kind=\"bar\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MSE for the models, we can see that Random Forest had the lowest mean squared error, suggesting that it was the lowest of the three models. Though, it was not the lowest MSE when predicting non-high mpg cars. The second best model is the logit, showing significantly lower MSE for total mse. The worst at predicting the outcome is the SVM showing a very high error rate for predicting outcomes, especially when compared to Logit and Random Forest outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
